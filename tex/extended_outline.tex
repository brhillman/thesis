%\documentclass[12pt]{article}

%\title{Evaluation of clouds and radiation in global climate models using instrument simulators}
%\author{Benjamin R. Hillman}

%\begin{document}

\chapter{Introduction}
[Motivation for doing all this work, and what we hope to accomplish.]

General circulation models (also referred to as ``global climate models'' or ``GCMs'') are tools used to make predictions about future climate change. There is ``considerable confidence'' that GCMs provide credible estimates of future climate change, according to the Intergovermental Panel on Climate Change (IPCC) Fourth Assessment Report (AR4) \cite{ar4_ch8}. This confidence stems from the physical basis of these models as well as their ability to simulate past and present climate. However, considerable uncertainties and shortcomings remain in these models and in their projections of future climate change, particularly in their representation of clouds.

Perturbations to the Earth's radiative forcing cause responses within the climate system which can either act to increase the perturbation (a positive feedback) or to decrease it (a negative feedback). Cloud feedback processes have been identified as one of the largest sources of uncertainty in GCMs. A 1990 study by Cess, et al. showed nearly a factor of three spread in the equilibrium climate sensitivity (a measure of the climate response to a radiative perturbation) across 17 GCMs, and attributed much of this spread to cloud feedbacks \cite{cess_et_al_1990}. A 2003 study by Colman similarly found cloud feedback to have the largest impact on the spread in climate sensitivity, compared with the combined water vapor and lapse rate feedback and with the albedo feedback \cite{colman_2003}. Other studies continue to identify cloud feedbacks as a major source of uncertainty in model climate sensitivity and in climate projections made by models (Webb, et al. 2006 \cite{webb_et_al_2006}, Stephens 2005 \cite{stephens_2005}, Bony, et al. 2006 \cite{bony_et_al_2006}), and indeed the IPCC still recognizes cloud feedback processes as likely being the primary source of the spread in climate sensitivity among GCMs as of the Fourth Assessment Report \cite{ar4_ch8}. In particular, the response of low-level clouds to climate change has been shown to account for a large amount of the spread in cloud feedbacks among models. Bony and Dufresne (2005) used dynamical compositing to show that regimes of large-scale subsidence had the largest impact on uncertainties in the cloud feedback in the tropics \cite{bony_and_dufresne_2005}. [Somthing about Webb et al., 2006 here, and what they have to say about low clouds? Or perhaps leave the low cloud portion out of this section?] 


\chapter{Methodology}
[Good place to discuss the observations and the simulator strategy in some detail.]
This study makes extensive use of the diagnostics provided by COSP. COSP has the potential to be implemented inline with the model code, or can be run offline if sufficient model output is available. This raises the question of which is the optimum approach. In this work it was found to be much more efficient and convenient to implement COSP inline with the model radiation code. To run COSP offline requires non-standard quantities to be output at very high temporal resolution in order to accumulate sufficient statistics and to reasonably depict the clouds, which vary on too short of time scales for statistics accumulated from monthly-mean fields to be of much use. Running COSP inline with the model gives the simulators access to the instanteous model fields, allowing the simulators to be run at the high temporal resolution needed, but statistics can be accumulated and only the monthly means of these statistics need be saved. This greatly reduces the disk space burden, and makes the whole process much more streamlined as the COSP output is saved in the model output history files. Additionally, this approach takes advantage of the parallelization handled by the model, greatly reducing the computational time required to obtain usable diagnostics.

The task of implementing COSP inline with both the CAM3 and AM2 model radiation code was then undertaken. At the time, neither modeling group had implemented COSP into their models, but the ISCCP simulator had been included in both. Implementing COSP was mostly a matter of just modifying the code used to call the ISCCP simulator to instead call COSP, in addition to some modifications to pass a few extra parameters to run the MISR and MODIS simulators. The active sensor simulators have not yet been implemented in these two models. The implementation was tested by comparing output from the ISCCP simulator called from COSP with output from the ISCCP simulator called from the original model code without COSP. The implementation was also tested against offline calculations with COSP using 3-hourly instantaneous model output fields.


\chapter{CAM3 and AM2 clouds in present-day climate}
\section{Introduction}
A necessary test of the validity of projections made by climate models is assessing their ability to reasonably simulate features of observed present-day climate. Although even perfect simulation of present-day climate does not necessarily mean that a given model will respond like the real world in a changing climate, it is reasonable to assume that any model that poorly simulates present-day climate should not be trusted to produce credible simulations of climate change. Evaluation of simulated present-day climate against observations thus offers a necessary although insufficient test of the credibility of a climate model in making climate change projections.

This study will focus in particular on the relative performance of two climate models in simulating observed cloud property statistics and radiation. The CFMIP Observation Simulator Package is used to facilitate comparisons between modeled and observed cloud statistics, and to provide a common framework for comparison of the relative performance of the two models.

\section{Model and experiment set-up}
The two models evaluated here are the atmosphere-only components of the fully coupled climate system models produced by the National Center for Atmospheric Research (NCAR) and the Geophysical Fluid Dynamics Laboratory (GFDL) for the IPCC AR4. These models were chosen in particular for their known differing responses to climate change [citation needed], which will be of interest in the following chapter.

These two models differ in both their dynamics and physics. The version of the NCAR model used in this study is version 3.1.p2 of the Community Atmosphere Model (CAM3). The default Eulerian spectral dynamical core run with T42 resolution was used for all runs done for this study. This differs from the runs done for the IPCC AR4, which were done with T85 resolution [confirm this]. In the vertical, a hybrid coordinate is used with 26 vertical levels. [Brief discussion of physics here]. A full description of this model is available in Collins, et al. \cite{cam3_description}.

The version of the GFDL model used in this study is the ``memphis'' release of version 2 of the Atmosphere-only Model (AM2). The default finite volume dynamical core was used here with a horizontal resolution of [??144x64??]. This model also uses a hybrid vertical coordinate, but with 24 levels. [Brief discussion of physics here]. A more complete description of this model is available in Anderson, et al. \cite{am2_evaluation}.

The results shown in this section are from ``AMIP''-style runs done using this modified source code, and using monthly-mean sea-surface temperature data (hereafter cam3\_amip and am2\_amip). Both CAM3 and AM2 were run for the time period 1990-2000. Ideally, these runs would be performed for the same period for which we have observational data from the remote sensing instruments used in this study. For example, MISR data is only available back to March of 2000. However, the needed input data were not available to run CAM3 and AM2 beyond 2000. In fact, the input data for AM2 ends in 1999. Climatological mean sea-surface temperatures were then used to finish the last year of the AM2 run. [An argument should maybe be made here to justify using different time periods between the models and observations...it really shouldn't matter, but something should probably be said to justify this. Compare ISCCP 1990-2000 with 2000-2010 maybe] All runs in this section were done locally [reference to the resources that provided the ATG 623 cluster? Seems like some fund should be recognized that paid for these resources...]

\section{Global}
\section{Tropics}
\section{Subtropics}
\section{Mid-latitudes}
\section{High-latitudes?}
\section{Conclusions}

\chapter{CAM3 and AM2 cloud response to warming}
\section{Introduction}
Cloud feedback processes are recognized as being among the largest sources of inter-model spread in equilibrium climate sensitivity and in uncertainty in future projections of the earth climate system made by climate models [cite sources]. How these feedbacks respond to radiative forcings in the climate system is difficult to understand. A number of studies have been conducted to calculate the feedbacks in climate models [citations, Held and Soden, etc.]. A quantitative examination of feedbacks is not attempted here. Rather, the qualitative change in radiatively important cloud statistics are evaluated in a perturbed climate model run in an attempt to gain a general understanding of the response of the clouds in the model to climate change.

\section{Model and experiment set-up}
The same versions of the NCAR and GFDL models evaluated in the previous chapter are used here to evaluate qualitatively the response of the clouds in each model to climate change. Again instrument simulators are used extensively in the analyis. The benefit of the simulators in this case is not to facilite comparisons between model and observations, as observations for the perturbed climate are not available. Rather, the simulator approach allows comparisons of radiatively important cloud statistics between the control and perturbed model climates, as well as providing a common framework to compare the responses of the two models. In addition, this approach gives at least an estimate of how the real-world clouds might be expected to respond as seen by the available instruments in a similarly perturbed climate.

To simulate climate change in these experiments, again observed monthly-mean sea surface temperatures are used, but a uniform $+2$K and $+4$K temperature perturbation is applied. This approach was used by Cess et al. (1990) \cite{cess_et_al_1990} to assess cloud feedbacks. More realistic climate change scenarios may exist [Gettleman et al., in press], but this approach at least allows exploration of the qualitative nature of the cloud response in a climate change scenario. Each model was run with the observed monthly-mean sea surface temperatures from 1990-2000 with the temperature perturbation applied (a one-year spin-up with the perturbed input data was performed before starting the 1990-2000 period).

\section{Global}
\section{Tropics}
\section{Subtropics}
\section{Mid-latitudes}
\section{High-latitudes?}
\section{Conclusions}

\chapter{Assessing the evolution of clouds and radiation in successive versions of a GCM: from CAM3 to CAM5}
\section{Introduction}
Climate models are continually updated as understanding of the climate system improves and as computational resources and numerical techniques improve. One way in which climate models change from one generation to another is in the implementation of new sub-grid parameterization schemes to hopefully better represent the real-world system through improved physical representation. It is not necessarily the case that simply throwing more physics into a model improves the representation of the real climate system. It is important to critically evaluate the changes made to models to assess whether or not such changes actually constitute improvements to the model.

One method of assessing such changes in a model is by evaluating multiple versions of a given model against observations, and comparing the relative performance of each model. In this chapter, the affect of changing parameterization schemes on the representation of cloud statistics is explored by comparing evaluations of different versions of one particular model against observations using the instrument simulator technique.

\section{Model and experiment set-up}
The models used in this section are successive versions of the atmosphere component of the NCAR climate system model: CAM3, CAM4, and CAM5. 

[CAM3 discussed in previous chapters; refer to that here rather than describing it again.]

CAM4 contains much of the same physics as CAM3, but with changes to the deep convection and arctic cloud fraction parameterizations. A complete description of the model is provided in an NCAR Technical Note \cite{cam4_description}.

[Discuss new physics in CAM5]

\section{Global}
\section{Tropics}
\section{Subtropics}
\section{Mid-latitudes}
\section{High-latitudes?}
\section{Conclusions}

\chapter{Conclusions}

\chapter{Future}

%\end{document}
